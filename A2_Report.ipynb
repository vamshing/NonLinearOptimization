{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OR 506: HomeWork-2 \n",
    "**Created in iPython Notebook by Guduguntla Vamshi <gudugu@ncsu.edu>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.** Approximate the minimum value of the function : \n",
    "\\begin{equation}\n",
    "  f(x) = exp(-x) + x^2\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**i.Golden Section Method**\n",
    "Results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with Upper and Lower Bound  100 -100\n",
      "100.0 -23.6068\n",
      "52.7864 -23.6068\n",
      "23.6068 -23.6068\n",
      "23.6068 -5.57281\n",
      "12.46118 -5.57281\n",
      "5.57281 -5.57281\n",
      "5.57281 -1.31556\n",
      "2.94169 -1.31556\n",
      "1.31556 -1.31556\n",
      "1.31556 -0.31056\n",
      "0.69444 -0.31056\n",
      "0.69444 0.07331\n",
      "0.45719 0.07331\n",
      "0.45719 0.21994\n",
      "0.45719 0.31056\n",
      "0.40118 0.31056\n",
      "0.36657 0.31056\n",
      "0.36657 0.33195\n",
      "0.36657 0.34518\n",
      "0.3584 0.34518\n",
      "0.35335 0.34518\n",
      "0.35335 0.3483\n",
      "0.35335 0.35023\n",
      "0.35216 0.35023\n",
      "0.35216 0.35096\n",
      "0.35216 0.35142\n",
      "\n",
      "Converged after 26 iterations \n",
      "Point is :  0.351787\n"
     ]
    }
   ],
   "source": [
    "Golden_section(-100,100,.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comments on Result:\n",
    "- The tolerance for the convergence is set to be **0.001**\n",
    "- The upper bound is **100** and the lower bound is **-100**\n",
    "- Using the above values, the golden section implementation converged after **26** iterations.\n",
    "- Therefore, the point of minima is **0.351787**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm Implementation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import Libraries and setting the Golden ratio value\n",
    "import math\n",
    "R  = ((5 ** 0.5) - 1) / 2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# function definition\n",
    "def fun(x): return math.exp(-x) + x**2\n",
    "\n",
    "#method to compute the minima by golden section \n",
    "def Golden_section(lb,ub,tol):\n",
    "    iteration = 0          # counter to count the number of iterations \n",
    "    x1 = ub - ((ub-lb)*R)  # setting the x1 point by  golden ratio value property\n",
    "    x2 = lb + ((ub-lb)*R)  # setting the x2 point by  golden ratio value property\n",
    "    f1 = fun(x1)           \n",
    "    f2 = fun(x2)\n",
    "    print \"Starting with Upper and Lower Bound \",ub,lb\n",
    "    while (abs(ub-lb) > tol): #loop to check for the tolerance\n",
    "        iteration += 1       \n",
    "        if f1 < f2:           #condition to check for the location of minima, to the left\n",
    "            ub = x2\n",
    "            print round(ub,5),round(lb,5)\n",
    "            x2 = x1           # set the values accordingly\n",
    "            f2 = f1\n",
    "            x1 = ub - ((ub-lb)*R)\n",
    "            f1 = fun(x1)\n",
    "        else:\n",
    "            lb = x1           #condition otherwise\n",
    "            print round(ub,5),round(lb,5)\n",
    "            x1 = x2\n",
    "            f1 = f2\n",
    "            x2 = lb + ((ub-lb)*R)\n",
    "            f2 = fun(x2)\n",
    "\n",
    "    print \"\\nConverged after %g iterations \\nPoint is : \"%iteration,\n",
    "                                                    round(.5*(ub+lb),6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ii.BiSection Method**\n",
    "Results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with Upper and Lower Bound  100 -100\n",
      "100.0 0.0\n",
      "50.0 0.0\n",
      "25.0 0.0\n",
      "12.5 0.0\n",
      "6.25 0.0\n",
      "3.125 0.0\n",
      "1.5625 0.0\n",
      "0.78125 0.0\n",
      "0.39063 0.0\n",
      "0.39063 0.19531\n",
      "0.39063 0.29297\n",
      "0.39063 0.3418\n",
      "0.36621 0.3418\n",
      "0.354 0.3418\n",
      "0.354 0.3479\n",
      "0.354 0.35095\n",
      "0.35248 0.35095\n",
      "0.35248 0.35172\n",
      "\n",
      "Converged after 18 iterations \n",
      "Point is :  0.352097\n"
     ]
    }
   ],
   "source": [
    "Bi_section(-100,100,.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comments on Result:\n",
    "- The tolerance for the convergence is set to be **0.001**\n",
    "- The upper bound is **100** and the lower bound is **-100**\n",
    "- Using the above values, the golden section implementation converged after **18** iterations.\n",
    "- Therefore, the point of minima is **0.352097**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm Implementation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fun(x): return math.exp(-x) + x**2 \n",
    "def fun_derv(x): return -math.exp(-x) + 2*x  #function to return the derivative\n",
    "def Bi_section(lb,ub,tol): #method to compute the minima by bisection \n",
    "    iteration = 0\n",
    "    c = .5*(lb+ub)\n",
    "    fc = fun_derv(c)\n",
    "    print \"Starting with Upper and Lower Bound \",ub,lb\n",
    "    while (abs(ub-lb) > tol):\n",
    "        iteration += 1 # counter to count the number of iterations \n",
    "        if fc < 0: #check for the derivative of the point whether negative\n",
    "            lb = c     # setting the lb point by golden bisection method\n",
    "            print round(ub,5),round(lb,5)\n",
    "            c = .5*(lb+ub) # setting the c point by taking the mean\n",
    "            fc = fun_derv(c) #check for the derivative\n",
    "        else:\n",
    "            ub = c\n",
    "            print round(ub,5),round(lb,5)\n",
    "            c = .5*(lb+ub)\n",
    "            fc = fun_derv(c)\n",
    "\n",
    "    print \"\\nConverged after %g iterations \\nPoint is : \"\n",
    "                                    %iteration,round(.5*(ub+lb),6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**2.i** Newtons Method : \n",
    "\\begin{equation}\n",
    "  f(x) =7x^4 + 3x^3 + 2x^2 + 9x + 4 = 0\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**i.Newtons Method**\n",
    "Results:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comments on Result:\n",
    "- The tolerance for the convergence is set to be **0.000001**\n",
    "- Using the initial guess as **-1** approxiamated value of x is **-0.909306388848**\n",
    "- Using the initial guess as **1** approxiamated value of x is **-0.511041787678**\n",
    "- Since it is the order four equation, and with other trials, I found that the method converges to these two values only. Hence, the other two roots are **complex**\n",
    "- The computed values are cross-validates by checking plugging in these values and and checking for convergence ~0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solve for x in 7*x**4 + 3*x**3 + 2*x**2 + 9*x + 4 = 0\n",
      "x = -0.909306388848\n",
      "Testing with the above x value ...\n",
      "0.000000000487\n"
     ]
    }
   ],
   "source": [
    "x_approx = -1  # rough guess\n",
    "x = newtons_method(f, x_approx) #compute\n",
    "print(\"Solve for x in 7*x**4 + 3*x**3 + 2*x**2 + 9*x + 4 = 0\")\n",
    "print(\"x = %0.12f\" % x)\n",
    "print(\"Testing with the above x value ...\")\n",
    "print(\"%0.12f\" % (7*x**4 + 3*x**3 + 2*x**2 + 9*x + 4))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solve for x in 7*x**4 + 3*x**3 + 2*x**2 + 9*x + 4 = 0\n",
      "x = -0.511041787678\n",
      "Testing with the above x value ...\n",
      "0.000000002000\n"
     ]
    }
   ],
   "source": [
    "x_approx = 1  # rough guess\n",
    "x = newtons_method(f, x_approx)\n",
    "print(\"Solve for x in 7*x**4 + 3*x**3 + 2*x**2 + 9*x + 4 = 0\")\n",
    "print(\"x = %0.12f\" % x)\n",
    "print(\"Testing with the above x value ...\")\n",
    "print(\"%0.12f\" % (7*x**4 + 3*x**3 + 2*x**2 + 9*x + 4))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation of Newtons method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def derivative(f): #method to compute the derivative\n",
    "    def compute(x, dx):\n",
    "        return (f(x+dx) - f(x))/dx\n",
    "    return compute\n",
    "\n",
    "def newtons_method(f, x, dx=0.000001, tolerance=0.000001): #newton method\n",
    "    df = derivative(f)\n",
    "    while True:\n",
    "        x1 = x - f(x)/df(x, dx) # loop to check\n",
    "        t = abs(x1 - x) # taking the absolute value for convergence\n",
    "        if t < tolerance:\n",
    "            break # breaks out the loops to return the value of x \n",
    "        x = x1\n",
    "    return x\n",
    "\n",
    "def f(x):\n",
    "    return 7*x**4 + 3*x**3 + 2*x**2 + 9*x + 4 # the function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.ii** Newtons Method for solving simultaneous equations: \n",
    "\\begin{equation}\n",
    "  f(x,y) = 3xy + 7x + 2y - 3 \\\\\n",
    "  g(x,y) = 5xy - 9x - 4y + 6\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result and Comments:\n",
    "- The tolerance vector for the convergence is set to be **0.000001**\n",
    "- Using the initial guess as **[-2,-2]** approxiamated value of x is **[0.693548,-0.454545]**\n",
    "- Using the initial guess as **[2,2]** approxiamated value of x is **[0.0,1.5]**\n",
    "- The algorithm converged in **7** iterations using the above guess vector\n",
    "- The computed values are cross-validates by checking plugging in these values and and checking for convergence ~0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration :1 the guess vector is: 1.711111 -3.322222\n",
      "Iteration :2 the guess vector is: 1.073013 -1.523944\n",
      "Iteration :3 the guess vector is: 0.792685 -0.733929\n",
      "Iteration :4 the guess vector is: 0.704569 -0.485602\n",
      "Iteration :5 the guess vector is: 0.693718 -0.455024\n",
      "Iteration :6 the guess vector is: 0.693548 -0.454546\n",
      "Iteration :7 the guess vector is: 0.693548 -0.454545\n",
      "\n",
      "The function value has converged! -0.0 -0.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from sympy import symbols, diff\n",
    "def f1(x,y): #function 1\n",
    "    return 3*x*y + 7*x + 2*y - 3\n",
    "def f2(x,y): #function 2\n",
    "    return 5*x*y - 9*x - 4*y + 6\n",
    "def f1_x(x,y): #derivatives wrt x\n",
    "    return 3*y + 7\n",
    "def f1_y(x,y): #derivatives wrt y\n",
    "    return 3*x + 2\n",
    "def f2_x(x,y): #derivatives wrt x\n",
    "    return 5*y - 9\n",
    "def f2_y(x,y): #derivatives wrt x\n",
    "    return 5*x - 4\n",
    "def newton_equation(f1,f2,guess):\n",
    "    iteration = 0\n",
    "    while True:\n",
    "        iteration += 1 #compute the matrix of derivatives in Dx\n",
    "        Dx = np.matrix([[f1_x(guess.item(0),guess.item(1)),f1_y(guess.item(0),\n",
    "                                                                guess.item(1))],\n",
    "                        [f2_x(guess.item(0),guess.item(1)),f2_y(guess.item(0),\n",
    "                                                                guess.item(1))]])\n",
    "        Dx_inv = np.linalg.inv(Dx)    # inverse of the derivative matrix Dx               \n",
    "        function_vector = np.matrix([[f1(guess.item(0),guess.item(1))],\n",
    "                                     [f2(guess.item(0),guess.item(1))]])\n",
    "        #function vector\n",
    "        t = guess - np.dot(Dx_inv,function_vector) # new vector \n",
    "        function_vector1 = np.matrix([[f1(t.item(0),t.item(1))],\n",
    "                                      [f2(t.item(0),t.item(1))]])\n",
    "        #function value at new vector\n",
    "        print \"Iteration :%g the guess vector is:\"%iteration,\n",
    "                                    round(t.item(0),6),round(t.item(1),6)\n",
    "        if (abs(function_vector1.item(0)) < 0.00000000001 and \n",
    "                                abs(function_vector1.item(1)) < 0.00000000001):\n",
    "            break\n",
    "        guess = t #re-initialzing the guess vector to the computed value of current vector\n",
    "    print \"\\nThe function value has converged!\",round(function_vector1.item(0)),\n",
    "                                                            round(function_vector1.item(1))\n",
    "guess = np.matrix([[-2],[-2]])\n",
    "newton_equation(f1,f2,guess)             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**using the guess vector as [2,2]**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Iteration :1 the guess vector is: -0.314286 2.385714\n",
    "Iteration :2 the guess vector is: -0.07471 1.710546\n",
    "Iteration :3 the guess vector is: -0.006621 1.51866\n",
    "Iteration :4 the guess vector is: -6.2e-05 1.500175\n",
    "Iteration :5 the guess vector is: -0.0 1.5\n",
    "Iteration :6 the guess vector is: -0.0 1.5\n",
    "\n",
    "The function value has converged! -0.0 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The other root is **[0,1.5]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
